{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb2e106-a3c1-4365-89bd-d47a6640c472",
   "metadata": {},
   "source": [
    "# TCP Classification - Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed29f4e-38c7-4885-a339-16ab47bc51a0",
   "metadata": {},
   "source": [
    "This notebook assumes the CapstoneProject_eda notebook was run to generate the cleaned and labeled data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa2201b-9c47-4914-83d6-ce7b61d8df1d",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081dd34-5fb9-43a4-acc9-67ba2c30ad2e",
   "metadata": {},
   "source": [
    "### Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bb2774-e9a8-4eb3-a17b-20436e4cade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881225cb-8941-4ba5-8eeb-8b12c4884896",
   "metadata": {},
   "source": [
    "### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dd27e8-d40c-41af-b191-ad4a9d7d0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7d125-8667-4e69-bb86-0ef3a452a034",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf6ee0-ca12-4852-8be4-ad1c60afdc94",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "975c0b1f-107b-48f5-a40d-35a8a1d1b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf93307-2e62-40c1-b7f0-645c1d1c2b45",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7109c6c3-4b41-40c3-b78d-13c0c68ccbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "logistic_cv_scores = cross_val_score(logistic_model, X, y, cv=5, scoring=f1_scorer, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027a947-d3f4-43c6-b193-a888c7f8380c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbf9ddc-b588-4400-b6f1-3e2a9e309b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring=f1_scorer, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d47da2-8a0f-4f60-8fd4-84566c9c468a",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "733578a8-96be-47db-973d-bd8c174e0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "svm_cv_scores = cross_val_score(svm_model, X, y, cv=5, scoring=f1_scorer, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be9c8b-9311-4e77-a913-1c89b3be623c",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236af09-a3a3-499e-b16d-6e5cca6c1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic Regression CV F1 Scores: {logistic_cv_scores}\")\n",
    "print(f\"Logistic Regression Mean F1 Score: {logistic_cv_scores.mean()}\")\n",
    "\n",
    "print(f\"Random Forest CV F1 Scores: {rf_cv_scores}\")\n",
    "print(f\"Random Forest Mean F1 Score: {rf_cv_scores.mean()}\")\n",
    "\n",
    "print(f\"SVM CV F1 Scores: {svm_cv_scores}\")\n",
    "print(f\"SVM Mean F1 Score: {svm_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34d45e-7094-43da-a301-ed36e087f528",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e7174-14b2-426e-b8ae-d83f54373177",
   "metadata": {},
   "source": [
    "### Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4880c522-d853-4660-b8b1-4434bf83ed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=42), param_grid_lr, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters for Logistic Regression: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best F1-Score for Logistic Regression: {grid_search_lr.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc2ad1-9d4f-46d6-9d8d-b43e1b589e15",
   "metadata": {},
   "source": [
    "### Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac90cf-4a8d-407e-a8a4-f58101d75684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best F1-Score for Random Forest: {grid_search_rf.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb3343-affe-4af9-aafe-53df84ae934a",
   "metadata": {},
   "source": [
    "### SVM Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90b15c-2755-4173-9e1e-37761a158d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters for SVM: {grid_search_svm.best_params_}\")\n",
    "print(f\"Best F1-Score for SVM: {grid_search_svm.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2a753-87f7-4e6d-8044-c33509b3e900",
   "metadata": {},
   "source": [
    "## 4. Interpretation of Model's Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649406a-8719-4b08-8b30-74667cc57ab2",
   "metadata": {},
   "source": [
    "### Interpretation of Logistic Regression Results\n",
    "The Logistic Regression model was evaluated using 5-fold cross-validation with the F1-score as the evaluation metric. The F1-score is a measure of a test's accuracy and considers both precision and recall. The best parameters found using Grid Search were [Best parameters here]. The mean F1-score achieved with these parameters was [Best F1-Score here]. This indicates that the model has a balanced performance in terms of precision and recall for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66503f18-f974-4d5e-aa87-a19359470c16",
   "metadata": {},
   "source": [
    "### Interpretation of Random Forest Results\n",
    "The Random Forest model was evaluated using 5-fold cross-validation with the F1-score as the evaluation metric. The best parameters found using Grid Search were [Best parameters here]. The mean F1-score achieved with these parameters was [Best F1-Score here]. This suggests that the Random Forest model is effective in handling the imbalanced nature of the dataset, providing a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63685fa-a8a6-4c07-acfd-a44920caf7b1",
   "metadata": {},
   "source": [
    "### Interpretation of SVM Results\n",
    "The SVM model was evaluated using 5-fold cross-validation with the F1-score as the evaluation metric. The best parameters found using Grid Search were [Best parameters here]. The mean F1-score achieved with these parameters was [Best F1-Score here]. This indicates that the SVM model can effectively classify the data with a good balance between precision and recall, given the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b46411-aa46-4c09-ada9-6be415037fc7",
   "metadata": {},
   "source": [
    "## 5. Explanation and Rationale for the Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aebea8-0b23-4c7e-a25c-93dd0e700559",
   "metadata": {},
   "source": [
    "### Evaluation Metric: F1-Score\n",
    "The F1-score was chosen as the evaluation metric for this classification task. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both false positives and false negatives. This is particularly important for imbalanced datasets where one class may be more frequent than the other. By using the F1-score, we ensure that the model performs well in identifying both the positive and negative classes, providing a more robust evaluation of the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
